{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e9e09a-cd7f-42db-84ee-11fcef211731",
   "metadata": {},
   "source": [
    "### **Reflective Report - COMP6200 - 2024 - 48728705**\n",
    "#### A. Progress, Learning, and Development Process\n",
    "##### <u>1. Initial Challenges, Progress, and Future Aspirations</u>\n",
    "When I first started this course, I had minimal exposure to Jupyter notebooks and machine learning workflows. Initially, I found it difficult to organize my work effectively within the notebook structure. Managing data preprocessing, model training, and evaluations within a single environment was overwhelming. The transition from theoretical understanding to practical application using tools like `pandas`, `scikit-learn`, and visualization libraries, such as `matplotlib`, `seaborn`, was a major learning step.\n",
    "\n",
    "As I progressed, I began to appreciate the notebook's flexibility in writing code, documenting thoughts, and visualizing outputs. This method significantly enhanced my problem-solving skills, as I could incrementally refine my models and debug errors more efficiently. By the time I reached Portfolio 4, I was more adept at handling data preprocessing tasks such as **outlier detection**, **feature scaling**, and managing **missing values**—skills that were initially challenging but crucial for building effective machine learning models. Moreover, working on exploratory data analysis (EDA) also became smoother as I learned to apply techniques to identify trends, distributions, and anomalies in the dataset. In this way, it allowed me to have a thorough observation of datasets and critically prepare the data for predictive analysis. This laid a strong foundation for feature selection and model building, which is a crucial part of machine learning practices.\n",
    "\n",
    "Through this project, I realized the importance of automating data workflows and building reproducible code. Moving forward, I am interested in exploring *automated machine learning (AutoML)* techniques to enhance model optimization and deploying models in real-world applications. Additionally, I plan to focus on more advanced topics such as *deep learning* and *natural language processing (NLP)*, which I believe will further expand my knowledge and application skills.\n",
    "\n",
    "##### <u>2. Dataset Selection and Problem Identification</u>\n",
    "I selected a loan approval dataset for this portfolio due to its relevance in the financial sector and its balanced combination of **categorical** and **numerical** features, which offered an excellent opportunity to experiment with various machine learning algorithms. The problem was straightforward yet significant which is predicting whether a loan would be approved. In both Portfolio 3 and Portfolio 4, the primary objective was to **predict loan approval** based on a set of features related to the loan applicants’ personal, financial, and credit information. While the objective remained the same, the **structure and complexity of the datasets** provided distinct challenges, which justified revisiting the same goal with different datasets. The problem was well-defined, with the target variable clearly being **loan approval status**. This allowed me to structure the workflow from data cleaning to model selection and evaluation. Handling outliers and scaling the data were critical in ensuring the quality of the dataset, especially since some features (e.g., income, loan amount) contained extreme values.\n",
    "\n",
    "The dataset in Portfolio 4 contained fewer features (12 columns), focusing on core attributes like income, home ownership, and loan grade. While this dataset lacked the granularity of Portfolio 3, it was more concise and focused on capturing high-impact features that directly relate to loan decisions. The inclusion of loan intent and loan grade introduced a **more categorical structure** that required different handling compared to the numerical-heavy dataset in Portfolio 3. Despite the objective being the same, the two datasets required different preprocessing strategies, model evaluation techniques, and feature engineering approaches. In Portfolio 4, I focused on capturing the relationships between more fundamental features like loan amount, credit history, and default history, which simplified the model-building process but required more **careful handling of categorical features** like loan intent and home ownership status.\n",
    "\n",
    "##### <u>3. Model Selection and Insights</u>\n",
    "In Portfolio 4, I implemented *Logistic Regression*, *K-Nearest Neighbors (KNN)*, and a *Neural Network* (MLP). Each model was chosen based on its ability to handle binary classification tasks. Logistic Regression was selected for its interpretability, making it easier to understand the relationship between input features and loan approvals. KNN was used to explore a non-parametric model, and the Neural Network was implemented to capture **non-linear relationships**.\n",
    "\n",
    "After running these models, the **Neural Network** performed best in terms of accuracy, achieving over 90% accuracy on the test data. The results were consistent with my expectation that a more complex model could better capture the intricate relationships between the features. However, one key insight was that features like **employment length** and **credit history** were more influential than expected, playing a significant role in loan approval compared to traditional features like loan amount. The **class balancing techniques** I employed improved model performance on imbalanced target variables, highlighting the importance of addressing such issues in real-world datasets. The results were generally consistent with expectations, although the Neural Network's performance exceeded what I had initially predicted.\n",
    "\n",
    "#### B. Conclusion\n",
    "Portfolio 4 demonstrated significant progress in my ability to handle end-to-end data science tasks, from **data cleaning** to **model evaluation**. The practical experience gained through working with Jupyter notebooks has solidified my confidence in applying data science techniques to real-world problems. Therefore, I aim to leverage these skills in **advanced machine learning applications**, with a particular interest in deploying models in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
